{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Playing with our Sample Data\n",
    "\n",
    "At this point we have a sample of ten active bikes saved locally in `csv` format as `sample_trips.csv`. We need to grab that file and throw it through the wringer to format it into a GeoJSON store that can be consumed by `d3.js`. What wringer? Keep reading..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import json\n",
    "import os\n",
    "from polyline.codec import PolylineCodec\n",
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import mplleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_trips = pd.read_csv(\"../data/part_1/sample_trips.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_trips['starttime'] = sample_trips['starttime'].map(lambda x:\n",
    "                                                          np.datetime64(datetime.datetime.strptime(x, \"%Y-%d-%m %H:%M:%S\")))\n",
    "sample_trips['stoptime'] = sample_trips['stoptime'].map(lambda x:\n",
    "                                                        np.datetime64(datetime.datetime.strptime(x, \"%Y-%d-%m %H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need pass the data through the Google Maps API and passing it to a `GeoJSON`-formatted `dict` that we can save and have `d3.js` consume. This is a complex process.\n",
    "\n",
    "## Getting and Parsing Directions\n",
    "\n",
    "### Directions via the Google Maps API\n",
    "\n",
    "There's no way to know what path any of the bikers actually travelled. Maybe they had urgent business and needed to get there quickly, lest they miss a meeting. Or maybe they were just taking it on a tour of the town. We can make some attempt to classify trips as slow of fast based on their correspondance with average bike trips between the two stations in question, but knowing only the endpoints, that's the best we can.\n",
    "\n",
    "So instead we will call the points into the [Google Maps Directions API](https://developers.google.com/maps/documentation/directions/). I use the `googlemaps` module to do the deed. This will give us a \"best\" path for this trip (note that Google Maps tends to favor protected bike lanes in the results it returns when it's in Biking Mode, for obvious reasons). \n",
    "\n",
    "The entire trip is presented not as a single continuous entity either, but as a set of so-called \"legs\". Take the highway, turn right onto the road, etc. etc. Each of these legs has a polygon of coordinates, a polygon that is compressed into and returned as something called an [encoded polyline](https://developers.google.com/maps/documentation/utilities/polylinealgorithm). So effectively we have to loop over each leg in the path, collect the polyline, decode it, and concatenate that set of coordinates to our working list.\n",
    "\n",
    "\n",
    "### Side-note: Getting API Access\n",
    "\n",
    "You need to have your Google Maps API credentials stored locally at `../credentials/google_maps_api_key.json` using the following format for the next few lines to work:\n",
    "\n",
    "> `{ \"key\": \"...\" }`\n",
    "\n",
    "See the [Google Developer Console](https://console.developers.google.com/) for information getting your own API key. Note that you will need a *browser key*, specifically, not the related but functionally different *server key*.\n",
    "\n",
    "### Accounting for Rebalancing\n",
    "\n",
    "Far from every trip in the CitiBike system stems from an actual bike ride. The trouble with bikeshare systems is that they are source-to-sink&mdash;since the original user does not have to take the bike back to where they started, the bikes tend to accumulate over time at whatever stations are most popular. Since those stations themselves have limited out-of-station bandwith as well as their own peculiar destination patterns, the CitiBike system effectively functions as a huge [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
    "\n",
    "This explains the phenomenon that every New Yorker has probably seen but many perhaps cannot place, the sensation that racks are empty at certain stations at some times and in some areas and completely stuffed at others. These kinds of things get mathematicians very excited ([very very excited](http://www.citylab.com/commute/2014/08/balancing-bike-share-stations-has-become-a-serious-scientific-endeavor/379188/)), but on a day-to-day level they mean that bikes tend to have to be rebalanced by so-called bike vans or whatever-ya-call-thems.\n",
    "\n",
    "These trips do not show up as trips proper in the dataset. If you don't account for rebalancing trips you will be left wondering why your bike is teleporting around from time to time! They're fairly easily dispatched once you're aware of them, however.\n",
    "\n",
    "In visualization terms my plan is to plot these trips exactly midway between the trips around them, with the simulated time taken dependent on the estimated time given by the Google Maps API. Note that this requires making a call to the Google Maps API in a different mode&mdash;the regular, car-based one, in this case, instead of the bike one we use for real trips.\n",
    "\n",
    "Of course in reality the bikes tend to get ferried around all whily-nilly as all the errant bikes are collected for transfering (at least I assume, I actually have no idea how this stuff is done). But the whole thing is a simulation anyway so pipe down!\n",
    "\n",
    "### Bike Trips, Rebalancing Trips\n",
    "\n",
    "There are two cases under consideration here, **bike trips** and **rebalancing trips**.\n",
    "\n",
    "In the case of bike trips we throw the start point and end point at the Google Maps API (in bike mode), extract the polyline, throw out the rest of the data, and embed the properties we have from the trips dataset into the GeoJSON `properties`.\n",
    "\n",
    "In the case of a rebalancing trip, everything is a little more complicated. We can detect rebalancing trips by looking at reported trips in the dataset in which the bike seems to \"warp\" between one station and another. We make a request to the Google Maps API (in standard car mode this time) and extract the polyline again, but also extract the time estimate Google gives us for the trip. We measure the time between the two stations end and start times, respectively, and throw the rebalancing trip time exactly in between, shearing it off if it turns out to be longer than the actual time allowed (as is theoretically possible). We populate the properties from the two stations' data and this time data before finally saving the built-out string to GeoJSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_credentials(filename='google_maps_api_key.json'):\n",
    "    path = '../credentials/{0}'.format(filename)\n",
    "    if os.path.isfile(path):\n",
    "        data = json.load(open(path))['key']\n",
    "        return data\n",
    "    else:\n",
    "        raise IOError(\n",
    "            'This API requires a Google Maps credentials token to work. Did you forget to define one?')\n",
    "        \n",
    "gmaps = googlemaps.Client(key=import_credentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I wrote and tested a method which passes directions to Google Maps, and parses it down to coordinates, and a `mplleaflet` mapper to check the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Tripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bike_trip_path(start, end, client):\n",
    "    req = client.directions(start, end, mode='bicycling')\n",
    "    polylines = [step['polyline']['points'] for step in [leg['steps'] for leg in req[0]['legs']][0]]\n",
    "    coords = []\n",
    "    for polyline in polylines:\n",
    "        coords += PolylineCodec().decode(polyline)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_path(coords):\n",
    "    x_coords = [coord[1] for coord in coords] # Notice the position swap!\n",
    "    y_coords = [coord[0] for coord in coords]\n",
    "    plt.hold(True)\n",
    "    plt.plot(x_coords, y_coords, 'b')\n",
    "    # mplleaflet.display(fig=plt.figure())\n",
    "    mplleaflet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following opens the full `Leaflet` plot in a seperate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_path = get_bike_trip_path([40.76727216,-73.99392888], [40.701907,-74.013942], gmaps) # actual path from the data\n",
    "plot_path(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)\n",
    "# Otherwise the OS might move the file before mplleaflet finishes visualizing it.\n",
    "\n",
    "try:\n",
    "    os.remove(\"../figures/geocoder_test_path.html\")\n",
    "except OSError:\n",
    "    pass\n",
    "os.rename(\"_map.html\", \"../figures/geocoder_test_path.html\") # Just to keep the directory tidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancing Tripper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That verifies that our bike tripper is working. How about a rebalancing tripper?\n",
    "\n",
    "This isn't the typical map function. Since we need context about the trip before and the trip after for this to work, we will need to iterate through the list of trips two at a time, spot differences in start and end points, and connect them up through the geocoder, requiring full GeoJSON output. In other words this isn't an operation that can be neatly vectorized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rebalancing_trip_path_time_estimate_tuple(start, end, client):\n",
    "    req = client.directions(start, end, mode='driving')\n",
    "    # return req\n",
    "    # Get the time estimates.\n",
    "    # Raw time estimate results are strings of the form \"1 min\", \"5 mins\", \"1 hour 5 mins\", \"2 hours 5 mins\", etc.\n",
    "    time_estimates_raw = [step['duration']['text'] for step in [leg['steps'] for leg in req[0]['legs']][0]]\n",
    "    time_estimate_mins = 0\n",
    "    for time_estimate_raw in time_estimates_raw:\n",
    "        # Can we really get an hour+ estimate biking within the city? Possibly not but I won't risk it.\n",
    "        if \"min\" in time_estimate_raw and \"hour\" not in time_estimate_raw:\n",
    "            time_estimate_mins += int(time_estimate_raw.split(\" \")[0])\n",
    "        elif \"hour\" in time_estimate_raw:\n",
    "            time_estimate_mins += 60 * int(time_estimate_raw.split(\" \")[0])\n",
    "            if \"min\" in time_estimate_raw:\n",
    "                time_estimate_mins += int(time_estimate_raw.split(\" \")[2])\n",
    "            else:\n",
    "                # Uh-oh.\n",
    "                pass\n",
    "    # Get the polylines.\n",
    "    polylines = [step['polyline']['points'] for step in [leg['steps'] for leg in req[0]['legs']][0]]\n",
    "    coords = []\n",
    "    for polyline in polylines:\n",
    "        coords += PolylineCodec().decode(polyline)\n",
    "    # Return\n",
    "    return coords, time_estimate_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(40.76723, -73.99396),\n",
       "  (40.76713, -73.99372),\n",
       "  (40.76713, -73.99372),\n",
       "  (40.76651, -73.99418),\n",
       "  (40.76621, -73.99442),\n",
       "  (40.76605, -73.99453),\n",
       "  (40.76589, -73.99466),\n",
       "  (40.76526, -73.99511),\n",
       "  (40.76497, -73.99532),\n",
       "  (40.76463, -73.99557),\n",
       "  (40.76401, -73.99602),\n",
       "  (40.76373, -73.99622),\n",
       "  (40.76339, -73.99647),\n",
       "  (40.76277, -73.99693),\n",
       "  (40.76256, -73.99708),\n",
       "  (40.76243, -73.99717),\n",
       "  (40.76213, -73.99739),\n",
       "  (40.76152, -73.99785),\n",
       "  (40.76085, -73.99832),\n",
       "  (40.76016, -73.99882),\n",
       "  (40.76011, -73.99885),\n",
       "  (40.75992, -73.99897),\n",
       "  (40.75953, -73.99924),\n",
       "  (40.75953, -73.99924),\n",
       "  (40.75906, -73.99957),\n",
       "  (40.75891, -73.99968),\n",
       "  (40.75868, -73.99984),\n",
       "  (40.75831, -74.00014),\n",
       "  (40.75768, -74.00059),\n",
       "  (40.75707, -74.00106),\n",
       "  (40.75677, -74.00128),\n",
       "  (40.75646, -74.00152),\n",
       "  (40.7562, -74.0017),\n",
       "  (40.75607, -74.00178),\n",
       "  (40.75594, -74.00188),\n",
       "  (40.7558, -74.002),\n",
       "  (40.75567, -74.0021),\n",
       "  (40.75522, -74.00244),\n",
       "  (40.75514, -74.00249),\n",
       "  (40.75504, -74.00256),\n",
       "  (40.75481, -74.00271),\n",
       "  (40.75418, -74.00313),\n",
       "  (40.75383, -74.00338),\n",
       "  (40.75371, -74.00347),\n",
       "  (40.75366, -74.00351),\n",
       "  (40.75362, -74.00354),\n",
       "  (40.75357, -74.00359),\n",
       "  (40.75353, -74.00363),\n",
       "  (40.75348, -74.00367),\n",
       "  (40.75343, -74.00372),\n",
       "  (40.75335, -74.00377),\n",
       "  (40.75326, -74.00383),\n",
       "  (40.75319, -74.00388),\n",
       "  (40.75266, -74.00428),\n",
       "  (40.75204, -74.00472),\n",
       "  (40.75142, -74.00517),\n",
       "  (40.75102, -74.00546),\n",
       "  (40.7508, -74.00563),\n",
       "  (40.7503, -74.00599),\n",
       "  (40.75018, -74.0061),\n",
       "  (40.75016, -74.00612),\n",
       "  (40.75016, -74.00612),\n",
       "  (40.75, -74.00628),\n",
       "  (40.74966, -74.00653),\n",
       "  (40.74955, -74.00661),\n",
       "  (40.74953, -74.0066),\n",
       "  (40.74951, -74.00659),\n",
       "  (40.74949, -74.00659),\n",
       "  (40.74947, -74.0066),\n",
       "  (40.74945, -74.00661),\n",
       "  (40.74937, -74.00667),\n",
       "  (40.74933, -74.0067),\n",
       "  (40.74926, -74.00675),\n",
       "  (40.74904, -74.00696),\n",
       "  (40.74891, -74.00705),\n",
       "  (40.74883, -74.00711),\n",
       "  (40.74879, -74.00713),\n",
       "  (40.74874, -74.00715),\n",
       "  (40.7487, -74.00718),\n",
       "  (40.74865, -74.0072),\n",
       "  (40.74861, -74.00723),\n",
       "  (40.74857, -74.00726),\n",
       "  (40.74852, -74.0073),\n",
       "  (40.74848, -74.00733),\n",
       "  (40.74844, -74.00737),\n",
       "  (40.74841, -74.00741),\n",
       "  (40.74838, -74.00744),\n",
       "  (40.74833, -74.00749),\n",
       "  (40.74819, -74.00764),\n",
       "  (40.74819, -74.00764),\n",
       "  (40.74814, -74.00769),\n",
       "  (40.7481, -74.00772),\n",
       "  (40.74806, -74.00776),\n",
       "  (40.74801, -74.0078),\n",
       "  (40.74796, -74.00783),\n",
       "  (40.74793, -74.00785),\n",
       "  (40.74788, -74.00786),\n",
       "  (40.74785, -74.00787),\n",
       "  (40.74755, -74.00793),\n",
       "  (40.74709, -74.00802),\n",
       "  (40.74689, -74.00806),\n",
       "  (40.74617, -74.00819),\n",
       "  (40.74593, -74.00822),\n",
       "  (40.74554, -74.0083),\n",
       "  (40.74527, -74.00835),\n",
       "  (40.74473, -74.00846),\n",
       "  (40.74457, -74.00847),\n",
       "  (40.74439, -74.0085),\n",
       "  (40.74404, -74.00858),\n",
       "  (40.74391, -74.00862),\n",
       "  (40.7437, -74.00866),\n",
       "  (40.74343, -74.00872),\n",
       "  (40.74325, -74.00875),\n",
       "  (40.74306, -74.00879),\n",
       "  (40.74294, -74.00881),\n",
       "  (40.74248, -74.00889),\n",
       "  (40.74222, -74.00894),\n",
       "  (40.74151, -74.00908),\n",
       "  (40.74109, -74.00918),\n",
       "  (40.74099, -74.0092),\n",
       "  (40.74088, -74.00923),\n",
       "  (40.74078, -74.00927),\n",
       "  (40.74067, -74.00932),\n",
       "  (40.74057, -74.00937),\n",
       "  (40.74046, -74.00942),\n",
       "  (40.74037, -74.00947),\n",
       "  (40.74027, -74.00954),\n",
       "  (40.74017, -74.0096),\n",
       "  (40.74006, -74.00967),\n",
       "  (40.73978, -74.00985),\n",
       "  (40.73968, -74.00991),\n",
       "  (40.73958, -74.00997),\n",
       "  (40.73946, -74.01002),\n",
       "  (40.73934, -74.01007),\n",
       "  (40.73934, -74.01007),\n",
       "  (40.73923, -74.0101),\n",
       "  (40.73912, -74.01012),\n",
       "  (40.73901, -74.01013),\n",
       "  (40.7389, -74.01014),\n",
       "  (40.73884, -74.01013),\n",
       "  (40.73859, -74.01012),\n",
       "  (40.73851, -74.01012),\n",
       "  (40.73814, -74.01008),\n",
       "  (40.73778, -74.01004),\n",
       "  (40.73764, -74.01003),\n",
       "  (40.73748, -74.01002),\n",
       "  (40.73697, -74.01007),\n",
       "  (40.73606, -74.01014),\n",
       "  (40.73541, -74.01019),\n",
       "  (40.73523, -74.0102),\n",
       "  (40.73466, -74.01025),\n",
       "  (40.73428, -74.01029),\n",
       "  (40.73396, -74.01032),\n",
       "  (40.7338, -74.01033),\n",
       "  (40.73322, -74.01038),\n",
       "  (40.73269, -74.01044),\n",
       "  (40.73257, -74.01044),\n",
       "  (40.7323, -74.01047),\n",
       "  (40.7321, -74.01049),\n",
       "  (40.7314, -74.01056),\n",
       "  (40.7312, -74.01058),\n",
       "  (40.73109, -74.01059),\n",
       "  (40.73057, -74.01063),\n",
       "  (40.72988, -74.01071),\n",
       "  (40.72974, -74.01072),\n",
       "  (40.7296, -74.01073),\n",
       "  (40.72931, -74.01076),\n",
       "  (40.72912, -74.01078),\n",
       "  (40.72754, -74.01095),\n",
       "  (40.72723, -74.01097),\n",
       "  (40.7268, -74.01103),\n",
       "  (40.72629, -74.0111),\n",
       "  (40.72585, -74.01118),\n",
       "  (40.7252, -74.01129),\n",
       "  (40.72509, -74.01131),\n",
       "  (40.7244, -74.01144),\n",
       "  (40.72421, -74.01147),\n",
       "  (40.72364, -74.01159),\n",
       "  (40.72301, -74.01171),\n",
       "  (40.72289, -74.01174),\n",
       "  (40.72244, -74.01184),\n",
       "  (40.72233, -74.01186),\n",
       "  (40.72224, -74.01187),\n",
       "  (40.72161, -74.012),\n",
       "  (40.72047, -74.01224),\n",
       "  (40.72033, -74.01228),\n",
       "  (40.72023, -74.01231),\n",
       "  (40.71917, -74.01255),\n",
       "  (40.71905, -74.01258),\n",
       "  (40.71899, -74.0126),\n",
       "  (40.71893, -74.01261),\n",
       "  (40.71862, -74.01268),\n",
       "  (40.71826, -74.01276),\n",
       "  (40.71797, -74.01284),\n",
       "  (40.71759, -74.01293),\n",
       "  (40.71725, -74.01303),\n",
       "  (40.71653, -74.01323),\n",
       "  (40.7164, -74.01326),\n",
       "  (40.71616, -74.01332),\n",
       "  (40.71589, -74.01339),\n",
       "  (40.7154, -74.01351),\n",
       "  (40.71528, -74.01354),\n",
       "  (40.71517, -74.01357),\n",
       "  (40.7145, -74.01374),\n",
       "  (40.7144, -74.01377),\n",
       "  (40.71427, -74.01381),\n",
       "  (40.71394, -74.01391),\n",
       "  (40.71379, -74.01395),\n",
       "  (40.71326, -74.01411),\n",
       "  (40.71308, -74.01416),\n",
       "  (40.71285, -74.01423),\n",
       "  (40.71276, -74.01426),\n",
       "  (40.71267, -74.01428),\n",
       "  (40.71258, -74.01431),\n",
       "  (40.71248, -74.01433),\n",
       "  (40.71166, -74.01454),\n",
       "  (40.71141, -74.01459),\n",
       "  (40.71132, -74.01461),\n",
       "  (40.7111, -74.01469),\n",
       "  (40.71105, -74.0147),\n",
       "  (40.71098, -74.01473),\n",
       "  (40.71091, -74.01475),\n",
       "  (40.71082, -74.01477),\n",
       "  (40.71069, -74.0148),\n",
       "  (40.71059, -74.01483),\n",
       "  (40.7105, -74.01485),\n",
       "  (40.7104, -74.01488),\n",
       "  (40.71025, -74.01493),\n",
       "  (40.71006, -74.01499),\n",
       "  (40.70999, -74.01501),\n",
       "  (40.70983, -74.01505),\n",
       "  (40.70971, -74.01509),\n",
       "  (40.70971, -74.01509),\n",
       "  (40.70935, -74.0152),\n",
       "  (40.70925, -74.01523),\n",
       "  (40.70916, -74.01527),\n",
       "  (40.70862, -74.01546),\n",
       "  (40.70777, -74.01577),\n",
       "  (40.7075, -74.01587),\n",
       "  (40.70721, -74.01598),\n",
       "  (40.70717, -74.016),\n",
       "  (40.70713, -74.01601),\n",
       "  (40.70711, -74.01603),\n",
       "  (40.70706, -74.01605),\n",
       "  (40.70702, -74.01608),\n",
       "  (40.70698, -74.01609),\n",
       "  (40.70694, -74.01611),\n",
       "  (40.70673, -74.0162),\n",
       "  (40.70671, -74.01621),\n",
       "  (40.70671, -74.01621),\n",
       "  (40.70646, -74.0163),\n",
       "  (40.70643, -74.01631),\n",
       "  (40.70637, -74.01633),\n",
       "  (40.70632, -74.01635),\n",
       "  (40.70513, -74.01682),\n",
       "  (40.70513, -74.01682),\n",
       "  (40.70497, -74.01689),\n",
       "  (40.70491, -74.0169),\n",
       "  (40.70488, -74.01691),\n",
       "  (40.70485, -74.01692),\n",
       "  (40.70483, -74.01692),\n",
       "  (40.70483, -74.01692),\n",
       "  (40.70482, -74.01689),\n",
       "  (40.70482, -74.01684),\n",
       "  (40.70479, -74.01667),\n",
       "  (40.70479, -74.0166),\n",
       "  (40.70479, -74.01653),\n",
       "  (40.7048, -74.01641),\n",
       "  (40.7048, -74.01632),\n",
       "  (40.70481, -74.01624),\n",
       "  (40.70482, -74.01612),\n",
       "  (40.70483, -74.01602),\n",
       "  (40.70484, -74.01593),\n",
       "  (40.70484, -74.01582),\n",
       "  (40.70484, -74.01574),\n",
       "  (40.70484, -74.01566),\n",
       "  (40.70483, -74.0156),\n",
       "  (40.70483, -74.01552),\n",
       "  (40.70481, -74.01542),\n",
       "  (40.7048, -74.01533),\n",
       "  (40.70478, -74.01524),\n",
       "  (40.70477, -74.01516),\n",
       "  (40.70474, -74.01501),\n",
       "  (40.7047, -74.01488),\n",
       "  (40.70469, -74.01479),\n",
       "  (40.70467, -74.01471),\n",
       "  (40.70465, -74.01463),\n",
       "  (40.70463, -74.01456),\n",
       "  (40.7046, -74.01448),\n",
       "  (40.70458, -74.01443),\n",
       "  (40.70456, -74.01438),\n",
       "  (40.70454, -74.01433),\n",
       "  (40.70453, -74.0143),\n",
       "  (40.70451, -74.01428),\n",
       "  (40.70451, -74.01428),\n",
       "  (40.70448, -74.01426),\n",
       "  (40.70447, -74.01426),\n",
       "  (40.70444, -74.01426),\n",
       "  (40.70441, -74.01426),\n",
       "  (40.70437, -74.01427),\n",
       "  (40.70433, -74.01428),\n",
       "  (40.70421, -74.0143),\n",
       "  (40.7037, -74.01439),\n",
       "  (40.70359, -74.01441),\n",
       "  (40.70337, -74.01445),\n",
       "  (40.70332, -74.01446),\n",
       "  (40.70329, -74.01446),\n",
       "  (40.70323, -74.01445),\n",
       "  (40.70319, -74.01445),\n",
       "  (40.70316, -74.01444),\n",
       "  (40.70305, -74.01441),\n",
       "  (40.70298, -74.01438),\n",
       "  (40.70291, -74.01434),\n",
       "  (40.70286, -74.01431),\n",
       "  (40.7028, -74.01427),\n",
       "  (40.70273, -74.01421),\n",
       "  (40.70264, -74.01411),\n",
       "  (40.70262, -74.0141),\n",
       "  (40.7024, -74.01383),\n",
       "  (40.7024, -74.01383),\n",
       "  (40.70223, -74.01382),\n",
       "  (40.70215, -74.01382),\n",
       "  (40.70209, -74.01392),\n",
       "  (40.70206, -74.01396),\n",
       "  (40.70202, -74.01399),\n",
       "  (40.70197, -74.01401),\n",
       "  (40.70191, -74.01401)],\n",
       " 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rebalancing_trip_path_time_estimate_tuple([40.76727216,-73.99392888], [40.701907,-74.013942], gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_list_of_rebalancing_frames_from_df(df):\n",
    "    frames = []\n",
    "    for a_minus_1, a in zip(range(len(df) - 1), range(1, len(df))):\n",
    "        delta = df.iloc[[a_minus_1, a]]\n",
    "        ind_1, ind_2 = delta.index.values\n",
    "        if delta.ix[ind_1, 'end station id'] == delta.ix[ind_2, 'start station id']:\n",
    "            continue\n",
    "        else:\n",
    "            frames.append(delta)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def rebalanced(delta_df):\n",
    "    ind_1, ind_2 = delta_df.index.values\n",
    "    if delta_df.ix[ind_1, 'end station id'] == delta_df.ix[ind_2, 'start station id']:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_rebalancing_geojson_repr(delta_df):\n",
    "    start_point = delta_df.iloc[0]\n",
    "    end_point = delta_df.iloc[1]\n",
    "    start_lat, start_long = start_point[[\"end station latitude\", \"end station longitude\"]]\n",
    "    end_lat, end_long = end_point[[\"start station latitude\", \"start station longitude\"]]\n",
    "    coords, time_estimate_mins = get_rebalancing_trip_path_time_estimate_tuple([40.76727216,-73.99392888],\n",
    "                                                                               [40.701907,-74.013942], gmaps)\n",
    "    midpoint_time = end_point['starttime'] + ((end_point['starttime'] - start_point['stoptime']) / 2)\n",
    "    rebalancing_start_time = midpoint_time - datetime.timedelta(minutes=time_estimate_mins / 2)\n",
    "    rebalancing_end_time = midpoint_time + datetime.timedelta(minutes=time_estimate_mins / 2)\n",
    "    if rebalancing_start_time < start_point['stoptime']:\n",
    "        rebalancing_start_time = start_point['stoptime']\n",
    "    if rebalancing_end_time > end_point['starttime']:\n",
    "        rebalancing_end_time = end_point['starttime']\n",
    "    attributes = {\n",
    "        \"tripduration\": time_estimate_mins * 60,\n",
    "        \"start station id\": start_point['end station id'],\n",
    "        \"end station id\": end_point['start station id'],\n",
    "        \"start station name\": start_point['end station name'],\n",
    "        \"end station name\": end_point['start station name'],\n",
    "        \"bikeid\": start_point[\"bikeid\"],\n",
    "        \"usertype\": \"Rebalancing\",\n",
    "        \"birth year\": 0.0,\n",
    "        \"gender\": 3.0,\n",
    "        \"start station latitude\": start_lat,\n",
    "        \"start station longitude\": start_long,\n",
    "        \"end station latitude\": end_lat,\n",
    "        \"end station longitude\": end_long,\n",
    "        \"starttime\": rebalancing_start_time.strftime(\"%Y-%d-%m %H:%M:%S\"),\n",
    "        \"stoptime\": rebalancing_end_time.strftime(\"%Y-%d-%m %H:%M:%S\")\n",
    "    }\n",
    "    return geojson.Feature(geometry=geojson.LineString(coords, properties=attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: This *may* not work!\n",
    "# sample_trips[sample_trips['bikeid'] == 17609].sort_values(by=\"starttime\").head(2).to_csv(\n",
    "#     \"../data/part_1/non_rebalanced_sample.csv\"\n",
    "# )\n",
    "\n",
    "# This definitely works.\n",
    "with open(\"../data/part_1/non_rebalanced_sample.csv\", \"w\") as f:\n",
    "    f.write(\"\"\"Index,tripduration,starttime,stoptime,start station id,start station name,start station latitude,start station longitude,end station id,end station name,end station latitude,end station longitude,bikeid,usertype,birth year,gender\n",
    "287273,1315.0,2016-03-06 12:35:00,2016-03-06 12:56:56,358.0,Christopher St & Greenwich St,40.73291553,-74.00711384,530.0,11 Ave & W 59 St,40.771522,-73.99054100000002,17609.0,Subscriber,1981.0,1.0\n",
    "719222,588.0,2016-03-06 14:38:55,2016-03-06 14:48:44,530.0,11 Ave & W 59 St,40.771522,-73.99054100000002,3163.0,Central Park West & W 68 St,40.7734066,-73.97782542,17609.0,Subscriber,1953.0,1.0\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_trips.head(2).to_csv(\"../data/part_1/rebalanced_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can go further, however, we have to address an issue that crops up. The Citibike dataset includes basic demographic information about bikes' users (`birth year` and `gender`) which is available only for subscribers (that is, records with `usertype=subscriber`). Non-subscribers (customers, probably primarily tourists, which are indicated by a `usertype=Customer` value) are not required to provide this data to ride, and so these columns are unavailable in these cases.\n",
    "\n",
    "The Citibike dataset encodes unknown `gender` as 0.0 (`1.0` is male, `2.0` is female) and it encodes unknown `birth year` as a blank space which `pandas` converts to an `np.nan` value. However, the `geojson` spec doesn't support `np.nan` or other such sentinal values, so if we try to pass a `birth year=np.nan` to `geojson.dumps` and/or validate our data it will not take. This is easy to fix: to maintain formatting consistency we simply replace `birth year=np.nan` with `birth year=0.0` (as with `gender`) using `pd.fillna()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_trips = sample_trips.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it a GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method reads the list of paths associated with a particular bicycle from our dataset and packages it into a `GeoJSON` `FeatureCollection` containing the bicycle's entire trip-week. `GeoJSON` is a format for geographic data that `d3` understands (they were invented by the same guy, in fact, the one and only Mike Bostock).\n",
    "\n",
    "The end result is going be a wrapper around a list of Features that look a lot like this:\n",
    "\n",
    "    {\"geometry\": {\"coordinates\": [[40.72838, -73.98717], [...], ...]], \"properties\": {\"bikeid\": 20249.0, \"birth year\": 1983.0, \"end station id\": 268.0, \"end station latitude\": 40.71910537, \"end station longitude\": -73.99973337, \"end station name\": \"Howard St & Centre St\", \"gender\": 1.0, \"start station id\": 236.0, \"start station latitude\": 40.7284186, \"start station longitude\": -73.98713956, \"start station name\": \"St Marks Pl & 2 Ave\", \"starttime\": \"2016-03-11 09:02:45\", \"stoptime\": \"2016-03-11 09:10:28\", \"tripduration\": 462.0, \"usertype\": \"Subscriber\"}, \"type\": \"LineString\"}, \"properties\": {}, \"type\": \"Feature\"}\n",
    "\n",
    "The difference between trip types is encoded in the `usertype` property. Bike trips have a `usertype` of `Subscriber` or `Customer`; rebalancing trips, by contrast, go under `rebalancing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_trips(df, bike_id, client):\n",
    "    feature_list = []\n",
    "    bike_df = df[df['bikeid'] == bike_id].sort_values(by='starttime')\n",
    "    for a_minus_1, a in zip(range(len(bike_df) - 1), range(1, len(bike_df))):\n",
    "        delta_df = bike_df.iloc[[a_minus_1, a]]\n",
    "        ind_1, ind_2 = delta_df.index.values\n",
    "#         print(ind_1, ind_2)\n",
    "#         print(delta_df.index.values)\n",
    "#         print(delta_df)\n",
    "        start = delta_df.ix[ind_1]\n",
    "        end = delta_df.ix[ind_2]\n",
    "        path = get_bike_trip_path([start['start station latitude'], start['start station longitude']],\n",
    "                                  [start['end station latitude'], start['end station longitude']],\n",
    "                                  client)\n",
    "        props = start.to_dict()\n",
    "        props['starttime'] = props['starttime'].strftime(\"%Y-%d-%m %H:%M:%S\")\n",
    "        props['stoptime'] = props['stoptime'].strftime(\"%Y-%d-%m %H:%M:%S\")\n",
    "        feature_list.append(geojson.Feature(geometry=geojson.LineString(path, properties=props)))\n",
    "        if rebalanced(delta_df):\n",
    "            feature_list.append(get_rebalancing_geojson_repr(delta_df))\n",
    "    return geojson.FeatureCollection(feature_list, properties={'bike_id': bike_id})\n",
    "\n",
    "\n",
    "#     for row in df[df['bikeid'] == bike_id].iterrows():\n",
    "#         trip = row[1]\n",
    "#         path = get_bike_path([trip['start station latitude'], trip['start station longitude']],\n",
    "#                              [trip['end station latitude'], trip['end station longitude']],\n",
    "#                              client)\n",
    "#         feature = geojson.Feature(geometry=geojson.LineString(path, properties=trip.to_dict()))\n",
    "#         feature_list.append(feature)\n",
    "#     return geojson.FeatureCollection(feature_list, properties={'bike_id': bike_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I'm working with only a single sample. Once I can verify that this sample works and get the frontend working around it, I can extend the method above to calling it on every bike in our sample dataset and extend the visualization around all of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random.choice(list(sample_trips['bikeid'].unique()))\n",
    "# We got back bikeid no. 20249, which is the bike that we will use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bike had 20 trips and 1 rebalancing. Manual inspection confirms that this is the case&mdash;our algorithm is good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_feature_collection = get_trips(sample_trips, 20249, gmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one_feature_collection # Too long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/part_1/one_trip.geojson', 'w') as outfile:\n",
    "    outfile.write(geojson.dumps(one_feature_collection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend So Far\n",
    "\n",
    "At this point we've taken the dataset, understood its structure, and generated a single trip's GeoJSON from the result.\n",
    "\n",
    "What we've done essentially is scoped out and proof-of-concepted the this system's backend. But in order to truly get to the target result here&mdash;a web application served on, well, the web&mdash;a way of operationalizing this backend must be found.\n",
    "\n",
    "1. A recurrent `chron` job on `PythonAnywhere` will run a script on my website at the beginning of every week which retrieves the files for CitiBike rides from the previous week (stitching together two months' data if necessary), picks ten active bikes, runs the algorithms above on them, gets a GeoJSON repr...\n",
    "2. and throws them into a `MySQL` data store, also on my `PythonAnywhere` website (this segment is the focus of `A Week in the Life of a CitiBikeâ€”Data Store Scoping`).\n",
    "3. When the visualization page is hit, it will send a request to an internal API, which will process and return a random GeoJSON selection from the `MySQL` data store.\n",
    "4. From there the front-end kicks in.\n",
    "\n",
    "For the intro screen I will also statically convert a selection of some fairly large number of random CitiBike paths and plop them onto the map."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
